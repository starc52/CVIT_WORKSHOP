{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND gate and OR gate perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47299109 0.4850712 ]\n",
      "0\n",
      "[0.37299109 0.3850712 ] 2\n",
      "1\n",
      "[0.27299109 0.2850712 ] 2\n",
      "2\n",
      "[0.17299109 0.1850712 ] 2\n",
      "3\n",
      "[0.17299109 0.1850712 ] 0\n"
     ]
    }
   ],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [0, 0, 0, 1]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "w = np.random.uniform(low=-1, high=1, size=2)\n",
    "# w = [0.3, -0.1]\n",
    "print(w)\n",
    "thresh = 0.2\n",
    "learning_rate = 0.1\n",
    "epoch_error=1\n",
    "def loss(y_pref, output):\n",
    "    return y_pref-output\n",
    "def activation(output):\n",
    "    if output>=thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "j=0\n",
    "while epoch_error!=0:\n",
    "    epoch_error=0\n",
    "    print(j)\n",
    "    j+=1\n",
    "#     pdb.set_trace()\n",
    "    for i in range(4):\n",
    "        teVal1 = np.dot(x[i], w)\n",
    "        teVal2 = activation(teVal1)\n",
    "        tempLoss=loss(y[i],teVal2)\n",
    "#         print(teVal1, teVal2, tempLoss)\n",
    "#         print(tempLoss)\n",
    "        delta = learning_rate*tempLoss*x[i]\n",
    "        w+=delta\n",
    "        epoch_error+=abs(tempLoss)\n",
    "        \n",
    "    print(w, epoch_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69235586  0.80823042]\n",
      "0\n",
      "[-0.59235586  0.80823042] 1\n",
      "1\n",
      "[-0.49235586  0.80823042] 1\n",
      "2\n",
      "[-0.39235586  0.80823042] 1\n",
      "3\n",
      "[-0.29235586  0.80823042] 1\n",
      "4\n",
      "[-0.19235586  0.80823042] 1\n",
      "5\n",
      "[-0.09235586  0.80823042] 1\n",
      "6\n",
      "[0.00764414 0.80823042] 1\n",
      "7\n",
      "[0.10764414 0.80823042] 1\n",
      "8\n",
      "[0.20764414 0.80823042] 1\n",
      "9\n",
      "[0.20764414 0.80823042] 0\n"
     ]
    }
   ],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [0, 1, 1, 1]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "w = np.random.uniform(low=-1, high=1, size=2)\n",
    "# w = [0.3, -0.1]\n",
    "print(w)\n",
    "thresh = 0.2\n",
    "learning_rate = 0.1\n",
    "epoch_error=1\n",
    "def loss(y_pref, output):\n",
    "    return y_pref-output\n",
    "def activation(output):\n",
    "    if output>=thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "j=0\n",
    "while epoch_error!=0:\n",
    "    epoch_error=0\n",
    "    print(j)\n",
    "    j+=1\n",
    "#     pdb.set_trace()\n",
    "    for i in range(4):\n",
    "        teVal1 = np.dot(x[i], w)\n",
    "        teVal2 = activation(teVal1)\n",
    "        tempLoss=loss(y[i],teVal2)\n",
    "#         print(teVal1, teVal2, tempLoss)\n",
    "#         print(tempLoss)\n",
    "        delta = learning_rate*tempLoss*x[i]\n",
    "        w+=delta\n",
    "        epoch_error+=abs(tempLoss)\n",
    "        \n",
    "    print(w, epoch_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47032194 -0.81934725]\n",
      "0\n",
      "[-0.37032194 -0.71934725] 2\n",
      "1\n",
      "[-0.27032194 -0.61934725] 2\n",
      "2\n",
      "[-0.17032194 -0.51934725] 2\n",
      "3\n",
      "[-0.07032194 -0.41934725] 2\n",
      "4\n",
      "[ 0.02967806 -0.31934725] 2\n",
      "5\n",
      "[ 0.12967806 -0.21934725] 2\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [0, 1, 1, 0]\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "w = np.random.uniform(low=-1, high=1, size=2)\n",
    "# w = [0.3, -0.1]\n",
    "print(w)\n",
    "thresh = 0.2\n",
    "learning_rate = 0.1\n",
    "epoch_error=1\n",
    "def loss(y_pref, output):\n",
    "    return y_pref-output\n",
    "def activation(output):\n",
    "    if output>=thresh:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "j=0\n",
    "epoch_curr_error=0\n",
    "prev_epoch_error=0\n",
    "count=0\n",
    "while epoch_error!=0:\n",
    "    prev_epoch_error=epoch_error\n",
    "    epoch_error=0\n",
    "    print(j)\n",
    "    j+=1\n",
    "#     pdb.set_trace()\n",
    "    for i in range(4):\n",
    "        teVal1 = np.dot(x[i], w)\n",
    "        teVal2 = activation(teVal1)\n",
    "        tempLoss=loss(y[i],teVal2)\n",
    "#         print(teVal1, teVal2, tempLoss)\n",
    "#         print(tempLoss)\n",
    "        delta = learning_rate*tempLoss*x[i]\n",
    "        w+=delta\n",
    "        epoch_error+=abs(tempLoss)\n",
    "    epoch_curr_error = epoch_error\n",
    "    if epoch_curr_error == prev_epoch_error:\n",
    "        count+=1\n",
    "    else:\n",
    "        count=0\n",
    "    if count>5:\n",
    "        break\n",
    "    print(w, epoch_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
